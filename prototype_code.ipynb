{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype Code for Data Generation and Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation and sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class named CustomData that generates the entire dataset and can return batches of data upon request during the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData:\n",
    "    \"\"\"\n",
    "    CustomData class generates the entire data set and can return samples\n",
    "    \"\"\"\n",
    "    def __init__(self,n_samples=1000,n_features=20,n_informative=8):\n",
    "        \"\"\"\n",
    "        n_samples: number of samples to be generated\n",
    "        n_features: number of all possible features\n",
    "        n_informative: number of features the model is based on\n",
    "        \"\"\"\n",
    "        self._n_samples = n_samples\n",
    "        self._n_features = n_features\n",
    "        self._n_informative = n_informative\n",
    "        self._n_targets = 1\n",
    "        self._bias = 1\n",
    "        self._effective_rank = 20\n",
    "        self._tail_strength = 0.7\n",
    "        self._noise = 0.1\n",
    "        self._shuffle = True\n",
    "        self._coef = True\n",
    "        self._random_state = 42\n",
    "        self._X, self._y, self._model = make_regression(self._n_samples,\n",
    "                                                       self._n_features,\n",
    "                                                       self._n_informative,\n",
    "                                                       self._n_targets,\n",
    "                                                       self._bias,\n",
    "                                                       self._effective_rank,\n",
    "                                                       self._tail_strength,\n",
    "                                                       self._noise,\n",
    "                                                       self._shuffle,\n",
    "                                                       self._coef,\n",
    "                                                       self._random_state)\n",
    "        self._collected = 0\n",
    "        index = range(1,self._n_samples+1)\n",
    "        columns = [\"feature {}\".format(i) for i in range(1,self._n_features+1)] + [\"labels\"]\n",
    "        self._complete_data = pd.DataFrame(np.c_[self._X,self._y], index, columns)\n",
    "    \n",
    "    def collect(self,n_instances,feature_list):\n",
    "        \"\"\"\n",
    "        Returns some data\n",
    "        n_instances: number of collected instances\n",
    "        feature_list: a list of features that are to be collected\n",
    "        \"\"\"\n",
    "        X = self._complete_data[[\"feature {}\".format(i) for i in feature_list]][self._collected:self._collected+n_instances].copy()\n",
    "        y = self._complete_data[[\"labels\"]][self._collected:self._collected+n_instances].copy()\n",
    "        self._collected += n_instances\n",
    "        return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following functions are defined to compute correlation matrices and vectors for input data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_matrix(X,y):\n",
    "    \"\"\"\n",
    "    Get correlation matrix for the given data instances X, and outputs y\n",
    "    \"\"\"\n",
    "    index = range(1,X.shape[0]+1)\n",
    "    n_features = X.shape[1]\n",
    "    columns = [\"feature {}\".format(i) for i in range(1,n_features+1)] + [\"labels\"]\n",
    "    data = pd.DataFrame(np.c_[X,y], index, columns)\n",
    "    corr_matrix = data.corr()\n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_vec(X,y):\n",
    "    \"\"\"\n",
    "    Get correlation vector between features of X and the labels y\n",
    "    \"\"\"\n",
    "    index = range(1,X.shape[0]+1)\n",
    "    n_features = X.shape[1]\n",
    "    columns = [\"feature {}\".format(i) for i in range(1,n_features+1)] + [\"labels\"]\n",
    "    data = pd.DataFrame(np.c_[X,y], index, columns)\n",
    "    corr_matrix = data.corr()\n",
    "    corr_vec = corr_matrix[\"labels\"].sort_values(ascending=False)\n",
    "    return corr_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a function prototype for feature selection, that returns a list of features depending on the input performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(measure):\n",
    "    \"\"\"\n",
    "    Selects and returns optimal features\n",
    "    \"\"\"\n",
    "    feature_list = list()\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a function prototype that adds collected data from the current batch to the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_memory(X_memo, x_batch, y_memo, y_batch):\n",
    "    \"\"\"\n",
    "    Add collected batch of data to memory\n",
    "    \"\"\"\n",
    "    X_memo = np.array(None)\n",
    "    y_memo = np.array(None)\n",
    "    return X_memo, y_memo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a function prototype for computing the performance measure given the history of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_measure(X_memo, y_memo):\n",
    "    \"\"\"\n",
    "    Compute performance measure to select the features accordingly\n",
    "    \"\"\"\n",
    "    measure = 0\n",
    "    return measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function prototype simulates a given step of feature selection and data collection procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_procedure(dataset,n_steps=10,n_vehicles=100):\n",
    "    \"\"\"\n",
    "    Simulates gradual data collection procedure\n",
    "    dataset: entire dataset including all future data\n",
    "    n_steps: number of steps\n",
    "    n_vehicles: number of vehicles to collect data from\n",
    "    \"\"\"\n",
    "    X_memo = np.array(None)\n",
    "    y_memo = np.array(None)\n",
    "    measure = 0\n",
    "    for step in range(n_steps):\n",
    "        selected_features = feature_selection(measure)\n",
    "        X_batch, y_batch = dataset.collect(n_vehicles, selected_features)\n",
    "        X_memo, y_memo = add_to_memory(X_memo, X_batch, y_memo, y_batch)\n",
    "        measure = compute_measure(X_memo, y_memo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code generates the data set and runs a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomData(n_samples=10000, n_features=20, n_informative=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_procedure(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
