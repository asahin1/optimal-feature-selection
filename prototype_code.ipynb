{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype Code for Data Generation and Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation and sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class named CustomData that generates the entire dataset and can return batches of data upon request during the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData:\n",
    "    \"\"\"\n",
    "    CustomData class generates the entire data set and can return samples\n",
    "    \"\"\"\n",
    "    def __init__(self,n_samples=1000,n_features=20,n_informative=8):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples: number of samples to be generated\n",
    "        n_features: number of all possible features\n",
    "        n_informative: number of features the model is based on\n",
    "        \"\"\"\n",
    "        self._n_samples = n_samples\n",
    "        self._n_features = n_features\n",
    "        self._n_informative = n_informative\n",
    "        self._n_targets = 1\n",
    "        self._bias = 1\n",
    "        self._effective_rank = 20\n",
    "        self._tail_strength = 0.7\n",
    "        self._noise = 0.1\n",
    "        self._shuffle = True\n",
    "        self._coef = True\n",
    "        self._random_state = 42\n",
    "        self._X, self._y, self._model = make_regression(self._n_samples,\n",
    "                                                       self._n_features,\n",
    "                                                       self._n_informative,\n",
    "                                                       self._n_targets,\n",
    "                                                       self._bias,\n",
    "                                                       self._effective_rank,\n",
    "                                                       self._tail_strength,\n",
    "                                                       self._noise,\n",
    "                                                       self._shuffle,\n",
    "                                                       self._coef,\n",
    "                                                       self._random_state)\n",
    "        self._collected = 0\n",
    "        index = range(1,self._n_samples+1)\n",
    "        columns = [\"feature {}\".format(i) for i in range(1,self._n_features+1)] + [\"labels\"]\n",
    "        self._complete_data = pd.DataFrame(np.c_[self._X,self._y], index, columns)\n",
    "    \n",
    "    def collect(self,n_instances,feature_list=0):\n",
    "        \"\"\"\n",
    "        Returns some data\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_instances: number of collected instances\n",
    "        feature_list: a list of features that are to be collected\n",
    "        Returns\n",
    "        X: X-matrix containing the values corresponding each instance and selected feature\n",
    "        y: y-vector containing the labels of each instance\n",
    "        -------\n",
    "        \"\"\"\n",
    "        if feature_list==0:\n",
    "            feature_list = range(1,self._n_features+1)\n",
    "        if self._collected + n_instances > self._n_samples:\n",
    "            print(\"Not enough samples to collect {} instances. Try a lower number of instances.\".format(n_instances))\n",
    "            print(\"Returning 0-by-|feature_list| X and 0-by-1 y.\")\n",
    "            return np.empty(shape=(0,len(feature_list))), np.empty(shape=(0,1))\n",
    "        X = self._complete_data[[\"feature {}\".format(i) for i in feature_list]][self._collected:self._collected+n_instances].copy()\n",
    "        y = self._complete_data[[\"labels\"]][self._collected:self._collected+n_instances].copy()\n",
    "        self._collected += n_instances\n",
    "        return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following functions are defined to compute correlation matrices and vectors for input data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_matrix(X,y):\n",
    "    \"\"\"\n",
    "    Get correlation matrix for the given data instances X, and outputs y\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: Input data X\n",
    "    y: Labels y\n",
    "    Returns\n",
    "    -------\n",
    "    corr_matrix: correlation matrix for each (feature,feature) and (feature,label) pair\n",
    "    \"\"\"\n",
    "    index = range(1,X.shape[0]+1)\n",
    "    n_features = X.shape[1]\n",
    "    columns = [\"feature {}\".format(i) for i in range(1,n_features+1)] + [\"labels\"]\n",
    "    data = pd.DataFrame(np.c_[X,y], index, columns)\n",
    "    corr_matrix = data.corr()\n",
    "    return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_vec(X,y):\n",
    "    \"\"\"\n",
    "    Get correlation vector between features of X and the labels y\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: Input data X\n",
    "    y: Labels y\n",
    "    Returns\n",
    "    -------\n",
    "    corr_vec: correlation vec (feature,label) pair\n",
    "    \"\"\"\n",
    "    index = range(1,X.shape[0]+1)\n",
    "    n_features = X.shape[1]\n",
    "    columns = [\"feature {}\".format(i) for i in range(1,n_features+1)] + [\"labels\"]\n",
    "    data = pd.DataFrame(np.c_[X,y], index, columns)\n",
    "    corr_matrix = data.corr()\n",
    "    corr_vec = corr_matrix[\"labels\"].sort_values(ascending=False)\n",
    "    return corr_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a function prototype for feature selection, that returns a list of features depending on the input parameters. To compute the reward for each feature, we use a formulation inspired from Upper-Confidence-Bound Action Selection(Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction. MIT press.) J is the value of each feature, c is the trade-off factor for exploitation and exploration, step represents the time, N is the number of samples collected for each feature, feature limit is the number of features that is desired to be collected.\n",
    "\n",
    "For features with $N=0$, reward is $\\infty$, meaning that each feature will be selected and some data will be collected before any real computations are made.\n",
    "\n",
    "$N$ includes the samples whose features are determined but values are not collected yet. This algorithm accounts for the features that are selected in the previous step but are still pending for data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(J,c,step,N,feature_limit):\n",
    "    \"\"\"\n",
    "    Selects and returns optimal features\n",
    "    Parameters\n",
    "    ----------\n",
    "    J: Value vector for features\n",
    "    c: Trade-off factor (exploitation vs. exploration)\n",
    "    step: Current time (t)\n",
    "    N: Number of samples collected for each feature (including previously selected features that are to be collected)\n",
    "    feature_limit: desired number of features to be selected\n",
    "    Returns\n",
    "    -------\n",
    "    feature_list: a list of selected features\n",
    "    \"\"\"\n",
    "    feature_list = list()\n",
    "    reward = list()\n",
    "    for feature in range(1,len(J)+1):\n",
    "        if N[feature-1] == 0:\n",
    "            reward.append(np.infty)\n",
    "        else:\n",
    "            reward.append(J[feature-1] + c*np.sqrt(np.log(step+1)/N[feature-1]))\n",
    "    while len(feature_list) < feature_limit:\n",
    "        feature_list.append(int(np.argmax(reward))+1)\n",
    "        reward[feature_list[-1]-1] = -1*np.infty\n",
    "        \n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a function prototype that adds collected data from the current batch to the memory. Note that $X_{memo}$ has a shape of $n_{samples} \\times n_{features}$. Therefore, only collected features will have non-zero entries when the sampled data is being transferred to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_memory(X_memo, X_batch, y_memo, y_batch, selected_features):\n",
    "    \"\"\"\n",
    "    Add collected batch of data to memory\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_memo: current X-matrix in memory\n",
    "    X_batch: collected data X\n",
    "    y_memo: current y-vector in memory\n",
    "    y_batch: assigned labels y\n",
    "    selected_features: features that the collected data X is based on\n",
    "    Returns\n",
    "    -------\n",
    "    X_memo: updated X-matrix in memory\n",
    "    y_memo: updated y-vector in memory\n",
    "    \"\"\"\n",
    "    X_append = np.zeros((X_batch.shape[0],X_memo.shape[1]))\n",
    "    y_append = np.zeros((y_batch.shape[0],y_memo.shape[1]))\n",
    "    idx = 0\n",
    "    for feature in selected_features:\n",
    "        X_append[:,feature-1] = X_batch[:,idx]\n",
    "        idx += 1\n",
    "    y_append = y_batch\n",
    "    X_memo = np.concatenate((X_memo, X_append))\n",
    "    y_memo = np.concatenate((y_memo, y_append))\n",
    "    return X_memo, y_memo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a function prototype for computing the feature values given the data in memory.\n",
    "\n",
    "Computation of $J$ is currently based on the correlation value between each feature and the label according to the entire data in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_J(X_memo, y_memo):\n",
    "    \"\"\"\n",
    "    Computes feature values J\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_memo: current X-matrix in memory\n",
    "    y_memo: current y-vector in memory\n",
    "    Returns\n",
    "    -------\n",
    "    J: list of computed feature values\n",
    "    \"\"\"\n",
    "    corr_measure = get_correlation_vec(X_memo, y_memo)\n",
    "    J = list()\n",
    "    for i in range(1,X_memo.shape[1]+1):\n",
    "        key = 'feature {}'.format(i)\n",
    "        if np.isnan(corr_measure[key]):\n",
    "            J.append(0)\n",
    "        else:\n",
    "            J.append(abs(corr_measure[key]))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a function prototype for updating the number of samples collected for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_N(N, selected_features, n_instances):\n",
    "    \"\"\"\n",
    "    Updates sample numbers N for each feature\n",
    "    Parameters\n",
    "    ----------\n",
    "    N: current number of samples of each feature\n",
    "    selected_features: selected features that require an update\n",
    "    n_instances: collected number of samples that are to be added\n",
    "    Returns\n",
    "    -------\n",
    "    N: updated list of sample numbers for each feature\n",
    "    \"\"\"\n",
    "    for feature in selected_features:\n",
    "        N[feature-1] += n_instances\n",
    "    return N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function prototype simulates a given step of feature selection and data collection procedures.\n",
    "\n",
    "We initialize $X_{memo}$ and $y_{memo}$ as empty matrix and vector, $J$ and $N$ are initialized to zeros. Trade-off factor is selected as 2. Previos features is initialized as an empty list.\n",
    "\n",
    "For given number of steps, we select features depending on the feature values $J$, trade-off factor $c$, current step number $step$, number of samples collected for each feature $N$, and the number of features to be selected $feature\\_limit$ (defaulted at 5). Then, we collect data using the previously selected features (assuming that there is a delay between the feature selection process and the collection of data, we can only collect data using the previously selected features). However, number of samples $N$ is updated using the most recently selected features. Collected data is added to memory, and feature values are computed depending on the data in memory. Lastly, selected features are passed on to previous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_procedure(dataset,n_steps=100,n_vehicles=100,feature_limit=5):\n",
    "    \"\"\"\n",
    "    Simulates gradual data collection procedure\n",
    "    dataset: entire dataset including all future data\n",
    "    n_steps: number of steps\n",
    "    n_vehicles: number of vehicles to collect data from\n",
    "    feature_limit: desired number of features to be selected\n",
    "    \"\"\"\n",
    "    X_memo = np.empty(shape=(0,dataset._n_features))\n",
    "    y_memo = np.empty(shape=(0,1))\n",
    "    J = np.zeros((dataset._n_features,1))\n",
    "    N = np.zeros((dataset._n_features,1))\n",
    "    c = 2\n",
    "    prev_features = list()\n",
    "    for step in range(n_steps):\n",
    "        selected_features = feature_selection(J,c,step,N,feature_limit)\n",
    "        print(\"Selected features in step {}:\".format(step))\n",
    "        print(selected_features)\n",
    "        X_batch, y_batch = dataset.collect(n_vehicles, prev_features)\n",
    "        N = update_N(N,selected_features, n_vehicles)\n",
    "        X_memo, y_memo = add_to_memory(X_memo, X_batch, y_memo, y_batch, prev_features)\n",
    "        J = update_J(X_memo, y_memo)\n",
    "        prev_features = selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code generates the data set and runs a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomData(n_samples=10000, n_features=20, n_informative=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features in step 0:\n",
      "[1, 2, 3, 4, 5]\n",
      "Selected features in step 1:\n",
      "[6, 7, 8, 9, 10]\n",
      "Selected features in step 2:\n",
      "[11, 12, 13, 14, 15]\n",
      "Selected features in step 3:\n",
      "[16, 17, 18, 19, 20]\n",
      "Selected features in step 4:\n",
      "[4, 3, 11, 9, 10]\n",
      "Selected features in step 5:\n",
      "[7, 19, 4, 17, 3]\n",
      "Selected features in step 6:\n",
      "[3, 9, 11, 10, 4]\n",
      "Selected features in step 7:\n",
      "[3, 4, 19, 9, 11]\n",
      "Selected features in step 8:\n",
      "[3, 9, 4, 8, 2]\n",
      "Selected features in step 9:\n",
      "[3, 9, 4, 11, 17]\n",
      "Selected features in step 10:\n",
      "[3, 9, 4, 11, 13]\n",
      "Selected features in step 11:\n",
      "[3, 9, 4, 11, 15]\n",
      "Selected features in step 12:\n",
      "[3, 9, 4, 11, 14]\n",
      "Selected features in step 13:\n",
      "[3, 9, 4, 11, 6]\n",
      "Selected features in step 14:\n",
      "[3, 9, 4, 11, 5]\n",
      "Selected features in step 15:\n",
      "[3, 9, 4, 11, 12]\n",
      "Selected features in step 16:\n",
      "[3, 9, 4, 11, 1]\n",
      "Selected features in step 17:\n",
      "[3, 9, 4, 11, 20]\n",
      "Selected features in step 18:\n",
      "[3, 9, 4, 11, 18]\n",
      "Selected features in step 19:\n",
      "[3, 9, 4, 11, 16]\n",
      "Selected features in step 20:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 21:\n",
      "[9, 3, 4, 11, 10]\n",
      "Selected features in step 22:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 23:\n",
      "[3, 9, 4, 11, 8]\n",
      "Selected features in step 24:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 25:\n",
      "[3, 9, 4, 11, 17]\n",
      "Selected features in step 26:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 27:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 28:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 29:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 30:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 31:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 32:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 33:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 34:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 35:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 36:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 37:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 38:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 39:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 40:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 41:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 42:\n",
      "[3, 9, 4, 11, 19]\n",
      "Selected features in step 43:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 44:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 45:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 46:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 47:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 48:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 49:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 50:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 51:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 52:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 53:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 54:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 55:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 56:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 57:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 58:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 59:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 60:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 61:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 62:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 63:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 64:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 65:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 66:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 67:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 68:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 69:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 70:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 71:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 72:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 73:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 74:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 75:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 76:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 77:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 78:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 79:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 80:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 81:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 82:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 83:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 84:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 85:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 86:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 87:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 88:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 89:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 90:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 91:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 92:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 93:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 94:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 95:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 96:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 97:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 98:\n",
      "[3, 9, 11, 4, 19]\n",
      "Selected features in step 99:\n",
      "[3, 9, 11, 4, 19]\n"
     ]
    }
   ],
   "source": [
    "simulate_procedure(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code provides the correlation vector using the entire dataset, and the actual model that is used to generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation vector obtained using entire dataset:\n",
      "================================\n",
      "labels        1.000000\n",
      "feature 3     0.468577\n",
      "feature 9     0.440805\n",
      "feature 11    0.405514\n",
      "feature 4     0.384567\n",
      "feature 19    0.378801\n",
      "feature 17    0.283558\n",
      "feature 10    0.272381\n",
      "feature 8     0.205915\n",
      "feature 14    0.048127\n",
      "feature 20    0.037011\n",
      "feature 15    0.029555\n",
      "feature 6     0.028081\n",
      "feature 7     0.025649\n",
      "feature 12    0.022933\n",
      "feature 2     0.022606\n",
      "feature 16    0.006147\n",
      "feature 1     0.005914\n",
      "feature 13   -0.001007\n",
      "feature 18   -0.004236\n",
      "feature 5    -0.024030\n",
      "Name: labels, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_vec = get_correlation_vec(dataset._X,dataset._y)\n",
    "print(\"Correlation vector obtained using entire dataset:\")\n",
    "print(\"================================\")\n",
    "print(corr_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual model of the system:\n",
      "================================\n",
      "y(x) ~= 90.99 x_3 + 63.61 x_4 + 39.22 x_8 + 88.86 x_9 + 39.04 x_10 + 65.27 x_11 + 63.08 x_17 + 72.97 x_19 \n"
     ]
    }
   ],
   "source": [
    "actual_model = dataset._model\n",
    "print(\"Actual model of the system:\")\n",
    "print(\"================================\")\n",
    "feature = 1\n",
    "model_eq = \"y(x) ~=\"\n",
    "for coef in actual_model:\n",
    "    if coef != 0:\n",
    "        model_eq += \" {:.2f} x_{} +\".format(coef,feature)\n",
    "    feature += 1\n",
    "if model_eq[-1] == \"+\":\n",
    "    actual_model_eq = model_eq[:-1]\n",
    "print(actual_model_eq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
